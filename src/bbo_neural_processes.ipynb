{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a418ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Computes the average target function output for the uniform baseline.\n",
    "'''\n",
    "\n",
    "\n",
    "from pyoptes.optimization.budget_allocation import target_function as f\n",
    "from pyoptes import create_graph, compute_average_otf_and_stderr\n",
    "from pyoptes import create_test_strategy_prior, map_low_dim_x_to_high_dim\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats.mstats import mjci\n",
    "\n",
    "\n",
    "def rms_tia(n_infected_animals):\n",
    "    values = n_infected_animals**2\n",
    "    estimate = np.sqrt(np.mean(values, axis=0))\n",
    "    stderr = np.std(values, ddof=1, axis=0) / np.sqrt(values.shape[0])\n",
    "    stderr = stderr/(2*estimate)\n",
    "    return estimate, stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6430ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_total_budget = 1\n",
    "n_nodes = 120\n",
    "sentinels = 12\n",
    "graph_type = 'syn'\n",
    "n_runs = 2\n",
    "n_simulations = 2\n",
    "path_networks = '../../networks/data'\n",
    "statistic = rms_tia\n",
    "n = 0\n",
    "total_budget = scale_total_budget * n_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d09a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "transmissions, capacities, degrees = create_graph(n, graph_type, n_nodes, path_networks)\n",
    "\n",
    "f.prepare(n_nodes=n_nodes,\n",
    "          capacity_distribution=capacities,\n",
    "          pre_transmissions=transmissions,\n",
    "          p_infection_by_transmission=0.5,\n",
    "          delta_t_symptoms=60,\n",
    "          expected_time_of_first_infection=30,\n",
    "          static_network=None,\n",
    "          use_real_data=False)\n",
    "\n",
    "# create a list of test strategies based on different heuristics\n",
    "prior, prior_node_indices, prior_parameter = \\\n",
    "    create_test_strategy_prior(n_nodes=n_nodes,\n",
    "                               node_degrees=degrees,\n",
    "                               node_capacities=capacities,\n",
    "                               total_budget=total_budget,\n",
    "                               sentinels=sentinels,\n",
    "                               mixed_strategies=True,\n",
    "                               only_baseline=False)\n",
    "\n",
    "# evaluate the strategies in the prior\n",
    "list_prior_tf = []\n",
    "list_prior_stderr = []\n",
    "\n",
    "for i, p in tqdm(enumerate(prior), leave=False, total=len(prior)):\n",
    "\n",
    "    p = map_low_dim_x_to_high_dim(x=p,\n",
    "                                  number_of_nodes=n_nodes,\n",
    "                                  node_indices=prior_node_indices[i])\n",
    "\n",
    "    m, stderr = f.evaluate(budget_allocation=p,\n",
    "                           n_simulations=n_simulations,\n",
    "                           parallel=True,\n",
    "                           num_cpu_cores=-1,\n",
    "                           statistic=statistic)\n",
    "    list_prior_tf.append(m)\n",
    "    list_prior_stderr.append(stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec1f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb485a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(list_prior_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520c6f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360b3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0005daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_process import NeuralProcess\n",
    "\n",
    "x_dim = 12\n",
    "y_dim = 1\n",
    "r_dim = 50  # Dimension of representation of context points\n",
    "z_dim = 50  # Dimension of sampled latent variable\n",
    "h_dim = 50  # Dimension of hidden layers in encoder and decoder\n",
    "\n",
    "neuralprocess = NeuralProcess(x_dim, y_dim, r_dim, z_dim, h_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c664ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of 100 target points, with shape \n",
    "# (batch_size, num_points, x_dim), which in this case is\n",
    "# (1, 100, 1)\n",
    "x_target = torch.Tensor(np.ones((100,12)))\n",
    "# x_target = [x_target, x_target]\n",
    "print(np.shape(x_target))\n",
    "x_target = x_target.unsqueeze(0)\n",
    "print(np.shape(x_target))\n",
    "for i in range(64):\n",
    "    z_sample = torch.randn((1, z_dim))  # Shape (batch_size, z_dim)\n",
    "    # Map x_target and z to p_y_target (which is parameterized by a \n",
    "    # normal with mean mu and std dev sigma)\n",
    "    mu, _ = neuralprocess.xz_to_y(x_target, z_sample)\n",
    "    # Plot predicted mean at each target point (note we could also\n",
    "    # sample from distribution but plot mean for simplicity)\n",
    "#     print(np.shape(mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8706127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class testdataset(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        print(np.shape(self.x))\n",
    "        print(np.shape(self.y))\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = testdataset(prior, list_prior_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import NeuralProcessTrainer\n",
    "\n",
    "batch_size = 2\n",
    "num_context = 4\n",
    "num_target = 4\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e837bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(neuralprocess.parameters(), lr=3e-4)\n",
    "np_trainer = NeuralProcessTrainer(device, neuralprocess, optimizer,\n",
    "                                  num_context_range=(num_context, num_context),\n",
    "                                  num_extra_target_range=(num_target, num_target), \n",
    "                                  print_freq=200)\n",
    "\n",
    "neuralprocess.training = True\n",
    "np_trainer.train(data_loader, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef44734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbo",
   "language": "python",
   "name": "bbo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
